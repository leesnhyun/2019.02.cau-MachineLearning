{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\title{Assignment 06}\n",
    "\\author{20142921 SengHyun Lee}\n",
    "\\date{2019.11.06}\n",
    "\\maketitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification based on 3 layers neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First layer\n",
    "\n",
    "$Z^{[1]} = W^{[1]} X + b^{[1]}$ : $X$ denotes the input data\n",
    "$A^{[1]} = g^{[1]}(Z^{[1]})$ : $g^{[1]}$ is the activation function at the first layer\n",
    "\n",
    "#### Second layer\n",
    "\n",
    "$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$\n",
    "\n",
    "$A^{[2]} = g^{[2]}(Z^{[2]})$ : $g^{[2]}$ is the activation function at the second layer\n",
    "\n",
    "#### Third layer\n",
    "\n",
    "$Z^{[3]} = W^{[3]} A^{[2]} + b^{[3]}$\n",
    "\n",
    "$A^{[3]} = g^{[3]}(Z^{[3]})$ : $g^{[3]}$ is the activation function at the third (output) layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library & GPU Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device : 0\n",
      "device count : 1\n",
      "device name : GeForce RTX 2060\n",
      "CUDA available? : True\n"
     ]
    }
   ],
   "source": [
    "# global settings\n",
    "# torch.set_default_dtype(torch.float64)\n",
    "torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "torch.set_printoptions(precision=16)\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# setting check\n",
    "print(\"current device : %s\" % (torch.cuda.current_device()))\n",
    "print(\"device count : %s\" % (torch.cuda.device_count()))\n",
    "print(\"device name : %s\" % (torch.cuda.get_device_name(0)))\n",
    "print(\"CUDA available? : %s\" % (torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_plot(g1, g2, title, color, label, legend):\n",
    "    plt.title(title)\n",
    "    plt.plot(np.arange(1, len(g1) + 1), g1, color=color[0], alpha=0.5, label=label[0])\n",
    "    plt.plot(np.arange(1, len(g2) + 1), g2, color=color[1], alpha=0.5, label=label[1])\n",
    "    plt.legend(loc=legend)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def output_frame_plot(tloss, vloss, tacc, vacc, title):\n",
    "    print(\" << %s >>\" % title)\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"                |   %10s    |    %10s     |\" % ('loss', 'accuracy'))\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"training        |   %.10f   |    %.10f    |\" % (tloss, tacc))\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"validation      |   %.10f   |    %.10f    |\" % (vloss, vacc))\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 100\n",
    "IMAGE_HEIGHT = 100\n",
    "IMAGE_CHANNEL = 1\n",
    "DIMENSION = IMAGE_CHANNEL * IMAGE_HEIGHT * IMAGE_WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train & validation datasets (preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* batch size = 3\n",
    "* number of epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(batch_size=3, num_workers=1):\n",
    "    transform = transforms.Compose([  # transforms.Resize((256,256)),\n",
    "        transforms.Grayscale(),\n",
    "        # the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "        transforms.ToTensor(), ])\n",
    "\n",
    "    # train_data_path = 'relative path of training data set'\n",
    "    # change the valuse of batch_size, num_workers for your program\n",
    "    # if shuffle=True, the data reshuffled at every epoch\n",
    "    train_data_path = './horse-or-human/train'\n",
    "    trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        dataset=trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    validation_data_path = './horse-or-human/validation'\n",
    "    valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        dataset=valset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    train_data = torch.empty((DIMENSION, 0), dtype=torch.double)\n",
    "    validation_data = torch.empty((DIMENSION, 0), dtype=torch.double)\n",
    "\n",
    "    train_label = torch.empty((1, 0))\n",
    "    validation_label = torch.empty((1, 0))\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        # inputs is the image\n",
    "        # labels is the class of the image\n",
    "\n",
    "        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "        # [batch_size, 1, height, width] => [ width * height * channel, batch_size ]\n",
    "        # x = inputs.transpose((2, 3, 0, 1)).reshape((DIMENSION, len(labels)))\n",
    "        x = np.array(inputs).transpose((2, 3, 0, 1)).reshape((DIMENSION, len(labels)))\n",
    "        x = torch.from_numpy(x.astype(np.double))\n",
    "        y = labels.reshape((1, len(labels))).type(torch.double)\n",
    "\n",
    "        x = x.to(0)\n",
    "        y = y.to(0)\n",
    "\n",
    "        train_data = torch.cat((train_data, x), dim=1)\n",
    "        train_label = torch.cat((train_label, y), dim=1)\n",
    "\n",
    "    # load validation images of the batch size for every iteration\n",
    "    for i, data in enumerate(valloader):\n",
    "        # inputs is the image\n",
    "        # labels is the class of the image\n",
    "        inputs, labels = data\n",
    "\n",
    "        # [batch_size, 1, height, width] => [ width * height * channel, batch_size ]\n",
    "        x = np.array(inputs).transpose((2, 3, 0, 1)).reshape((DIMENSION, len(labels)))\n",
    "        x = torch.from_numpy(x.astype(np.double))\n",
    "        y = labels.reshape((1, len(labels))).type(torch.double)\n",
    "\n",
    "        x = x.to(0)\n",
    "        y = y.to(0)\n",
    "\n",
    "        validation_data = torch.cat((validation_data, x), dim=1)\n",
    "        validation_label = torch.cat((validation_label, y), dim=1)\n",
    "\n",
    "    return train_data, validation_data, train_label, validation_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implements of 3 layers neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "* $g^{[1]}, g^{[2]}$ are Leaky ReLU ($\\alpha=0.001)$ and $g^{[3]}$ is Sigmoid\n",
    "* learning rate = $0.0005$\n",
    "* tolerance = $10^{-6}$\n",
    "* initialization : $Var(w_i) = \\frac{2}{n_{in}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input layer\n",
    "* num of features = $10000$ (100 * 100 image)\n",
    "* num of samples = $1027$ (number of training image samples)\n",
    "\n",
    "#### hidden layer 1\n",
    "* num of features (nodes) = $50$\n",
    "* activation function = Leaky ReLU\n",
    "\n",
    "#### hidden layer 2\n",
    "* num of features (nodes) = $150$\n",
    "* activation function = Leaky ReLU\n",
    "\n",
    "#### output layer\n",
    "* num of features (nodes) = $1$\n",
    "* activation function = Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemenations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classify(train_data, validation_data,\n",
    "                    train_label, validation_label,\n",
    "                    gn_act, gn_d_act, init, learning_rate=0.0002, regular_weight=0.01):\n",
    "\n",
    "    num_of_layers = 3\n",
    "\n",
    "    n = train_label.shape[1]\n",
    "\n",
    "    n1, n2 = 100, 150\n",
    "    learning_rate = learning_rate\n",
    "    regular_weight = regular_weight\n",
    "\n",
    "    epsilon = 10e-6\n",
    "\n",
    "    # INITIALIZE u v z\n",
    "    u, v, w = init(DIMENSION, n1, n2)\n",
    "\n",
    "    # INITIALIZE bias\n",
    "    b1 = torch.zeros((n1, 1))\n",
    "    b2 = torch.zeros((n2, 1))\n",
    "    b3 = torch.zeros((1, 1))\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    def _nan_to_num(tensor):\n",
    "        return tensor\n",
    "        # return torch.from_numpy(np.nan_to_num(tensor.cpu().numpy()))\n",
    "\n",
    "    # def safe_ln(x, minval=10e-20):\n",
    "    #     return np.log(x.clip(min=minval))\n",
    "\n",
    "    def sq_frobenius(mat):\n",
    "        return (torch.sum(mat ** 2)).item()\n",
    "\n",
    "    def cross_entropy(prob, ans):\n",
    "        return -((_nan_to_num(ans * torch.log(prob))) +\n",
    "                 (_nan_to_num((1 - ans) * torch.log(1-prob))))\n",
    "\n",
    "    def loss(prob, ans):\n",
    "        a = torch.sum(_nan_to_num(cross_entropy(prob, ans))).item() / ans.shape[1]\n",
    "        b = (regular_weight / (2*ans.shape[1])) * (sq_frobenius(u) + sq_frobenius(v) + sq_frobenius(w))\n",
    "        return a + b\n",
    "\n",
    "    def accuracy(prob, ans):\n",
    "        arr = (prob > 0.5).long()\n",
    "        arr = arr - ans.long()\n",
    "        arr = (arr == 0).long()\n",
    "        return torch.sum(arr).item() / ans.shape[1]\n",
    "\n",
    "    def iterate():\n",
    "        p_train_loss = 0\n",
    "        nonlocal u, v, w, b1, b2, b3\n",
    "        nonlocal train_losses, test_losses, train_accuracies, test_accuracies\n",
    "\n",
    "        while True:\n",
    "\n",
    "            # forward propagation #\n",
    "            act = gn_act()\n",
    "            next(act)\n",
    "            z1 = torch.mm(u.T, train_data) + b1\n",
    "            a1 = act.send(z1)\n",
    "\n",
    "            z2 = torch.mm(v.T, a1) + b2\n",
    "            a2 = act.send(z2)\n",
    "\n",
    "            z3 = torch.mm(w.T, a2) + b3\n",
    "            a3 = act.send(z3)\n",
    "\n",
    "            act = gn_act()\n",
    "            next(act)\n",
    "            vz = torch.mm(u.T, validation_data) + b1\n",
    "            vz = torch.mm(v.T, act.send(vz)) + b2\n",
    "            vz = torch.mm(w.T, act.send(vz)) + b3\n",
    "            ####\n",
    "\n",
    "            # back propagation #\n",
    "            d_act = gn_d_act()\n",
    "            next(d_act)\n",
    "            cw = (a3 - train_label)\n",
    "            dw = torch.mm(cw, a2.T) / z3.shape[1]\n",
    "\n",
    "            cv = torch.mm(w, cw) * d_act.send(z2)\n",
    "            dv = torch.mm(cv, a1.T) / z3.shape[1]\n",
    "\n",
    "            cu = torch.mm(v, cv) * d_act.send(z1)\n",
    "            du = torch.mm(cu, train_data.T) / z3.shape[1]\n",
    "\n",
    "            b3 = b3 - (learning_rate * (torch.sum(cw, dim=1, keepdim=True) / z3.shape[1]))\n",
    "            b2 = b2 - (learning_rate * (torch.sum(cv, dim=1, keepdim=True) / z3.shape[1]))\n",
    "            b1 = b1 - (learning_rate * (torch.sum(cu, dim=1, keepdim=True) / z3.shape[1]))\n",
    "\n",
    "            # gradient descent #\n",
    "            w = w - (learning_rate * dw).T - (learning_rate * (regular_weight * w)/n)\n",
    "            v = v - (learning_rate * dv).T - (learning_rate * (regular_weight * v)/n)\n",
    "            u = u - (learning_rate * du).T - (learning_rate * (regular_weight * u)/n)\n",
    "            ####\n",
    "\n",
    "            # get losses\n",
    "            t_hat, v_hat = a3, act.send(vz)\n",
    "\n",
    "            n_train_loss = loss(t_hat, train_label)\n",
    "            n_test_loss = loss(v_hat, validation_label)\n",
    "\n",
    "            # get accuracies\n",
    "            n_train_acc = accuracy(t_hat, train_label)\n",
    "            n_test_acc = accuracy(v_hat, validation_label)\n",
    "\n",
    "            train_losses.append(n_train_loss)\n",
    "            test_losses.append(n_test_loss)\n",
    "            train_accuracies.append(n_train_acc)\n",
    "            test_accuracies.append(n_test_acc)\n",
    "\n",
    "            if abs(p_train_loss - n_train_loss) < epsilon:\n",
    "                break\n",
    "            else:\n",
    "#                 print('tl: %s, vl: %s, ta: %s, va: %s' % (n_train_loss, n_test_loss, n_train_acc, n_test_acc))\n",
    "                p_train_loss = n_train_loss\n",
    "                continue\n",
    "\n",
    "    iterate()\n",
    "\n",
    "    return train_losses, test_losses, train_accuracies, test_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(title, learning_rate=0.015, regular_weight=49.195):\n",
    "\n",
    "    t_data, v_data, t_label, v_label = pre_process(batch_size=3)\n",
    "    train_loss, test_loss, train_acc, test_acc = [], [], [], []\n",
    "\n",
    "    # initialization functions\n",
    "    def he_initialize(n0, n1, n2):\n",
    "        u = np.random.randn(n0, n1) / np.sqrt(n0/2)\n",
    "        v = np.random.randn(n1, n2) / np.sqrt(n1/2)\n",
    "        w = np.random.randn(n2, 1) / np.sqrt(n2/2)\n",
    "        return u, v, w\n",
    "\n",
    "    def he_initialize2(n0, n1, n2):\n",
    "        u = np.random.randn(n0, n1) * np.sqrt(2 / (n0+n1))\n",
    "        v = np.random.randn(n1, n2) * np.sqrt(2 / (n1+n2))\n",
    "        w = np.random.randn(n2, 1) * np.sqrt(2 / (n2+1))\n",
    "        return u, v, w\n",
    "\n",
    "    def xaiver_initialize(n0, n1, n2):\n",
    "        u = torch.randn((n0, n1)) * math.sqrt(1 / n0)\n",
    "        v = torch.randn((n1, n2)) * math.sqrt(1 / n1)\n",
    "        w = torch.randn((n2, 1)) * math.sqrt(1 / n2)\n",
    "        return u, v, w\n",
    "\n",
    "    def gen_xaiver_initialize(n0, n1, n2):\n",
    "        u = torch.randn((n0, n1)) * math.sqrt(1 / (n0 + n1))\n",
    "        v = torch.randn((n1, n2)) * math.sqrt(1 / (n1 + n2))\n",
    "        w = torch.randn((n2, 1)) * math.sqrt(1 / (n2 + 1))\n",
    "        return u, v, w\n",
    "\n",
    "    def debug_initialize(n0, n1, n2):\n",
    "        u = torch.ones((n0, n1))\n",
    "        v = torch.ones((n1, n2))\n",
    "        w = torch.ones((n2, 1))\n",
    "        return u, v, w\n",
    "\n",
    "    # activation functions\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + torch.exp(-z))\n",
    "\n",
    "    def d_sigmoid(z):\n",
    "        return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "    # sigmoid\n",
    "    def case1(learning_rate, regular_weight):\n",
    "        def act():\n",
    "            z = yield\n",
    "            z = yield sigmoid(z)\n",
    "            z = yield sigmoid(z)\n",
    "            z = yield sigmoid(z)\n",
    "\n",
    "        def d_act():\n",
    "            z = yield\n",
    "            z = yield d_sigmoid(z)\n",
    "            z = yield d_sigmoid(z)\n",
    "\n",
    "        classify(\n",
    "            gn=act,\n",
    "            dgn=d_act,\n",
    "            learning_rate=learning_rate,\n",
    "            regular_weight=regular_weight,\n",
    "            init=xaiver_initialize\n",
    "        )\n",
    "        plot()\n",
    "\n",
    "    def classify(gn, dgn, learning_rate, regular_weight, init):\n",
    "        nonlocal train_loss, test_loss, train_acc, test_acc\n",
    "\n",
    "        train_loss, test_loss, train_acc, test_acc = binary_classify(\n",
    "            t_data, v_data,\n",
    "            t_label, v_label,\n",
    "            gn, dgn,\n",
    "            learning_rate=learning_rate,\n",
    "            regular_weight=regular_weight,\n",
    "            init=init\n",
    "        )\n",
    "\n",
    "    def plot():\n",
    "        output_plot(train_loss, test_loss,\n",
    "                    title=\"Loss (ENERGY) :: \" + title, color=('blue', 'red'),\n",
    "                    label=('train loss', 'validation loss'), legend='upper right')\n",
    "\n",
    "        output_plot(train_acc, test_acc,\n",
    "                    title=\"Accuracy :: \" + title, color=('blue', 'red'),\n",
    "                    label=('train accuracy', 'validation accuracy'), legend='lower right')\n",
    "\n",
    "        output_frame_plot(\n",
    "            train_loss[-1], test_loss[-1],\n",
    "            train_acc[-1], test_acc[-1],\n",
    "            title=title\n",
    "        )\n",
    "\n",
    "    case1(learning_rate=learning_rate, regular_weight=regular_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn(title=\"Sigmoid\", learning_rate=0.015, regular_weight=49.195)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
